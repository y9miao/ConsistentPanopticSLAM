{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. import library and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3168"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import depth_seg_utils\n",
    "import semantic_seg_utils\n",
    "from utils import *\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read images\n",
    "import rospy\n",
    "from cv_bridge import CvBridge\n",
    "import rosbag\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "rosbag_file = \"/media/yang/linux2/thesis_test/data/scenenn_231/scenenn_231.bag\"\n",
    "rgb_topic = \"/camera/rgb/image_raw\"\n",
    "depth_topic = \"/camera/depth/image_raw\"\n",
    "rgb_cam_info_topic = \"/camera/rgb/camera_info\"\n",
    "depth_cam_info_topic = \"/camera/depth/camera_info\"\n",
    "tf_topic = \"/tf\"\n",
    "\n",
    "bridge = CvBridge()\n",
    "bag = rosbag.Bag(rosbag_file, 'r')\n",
    "\n",
    "depth_msg_list = []\n",
    "rgb_msg_list = []\n",
    "\n",
    "depth_image_list = []\n",
    "rgb_image_list = []\n",
    "pose_list = []\n",
    "tf_list = []\n",
    "depth_cam_info = None\n",
    "\n",
    "for topic, msg, t in bag.read_messages(topics = [depth_topic,depth_cam_info_topic,rgb_topic,tf_topic]):\n",
    "    if topic == depth_cam_info_topic:\n",
    "        if depth_cam_info is None:\n",
    "            depth_cam_info = msg\n",
    "        \n",
    "    elif topic == depth_topic:\n",
    "        depth_img = bridge.imgmsg_to_cv2(msg)\n",
    "        depth_image_list.append(depth_img)\n",
    "        depth_msg_list.append(msg)\n",
    "\n",
    "    elif topic == rgb_topic:\n",
    "        rgb_img = bridge.imgmsg_to_cv2(msg)\n",
    "        rgb_image_list.append(rgb_img)\n",
    "        rgb_msg_list.append(msg)\n",
    "\n",
    "    elif topic == tf_topic:\n",
    "        tf_list.append(msg)\n",
    "        translation = msg.transforms[0].transform.translation\n",
    "        quat = msg.transforms[0].transform.rotation\n",
    "        r = R.from_quat([quat.x, quat.y, quat.z,quat.w])\n",
    "        rotation = r.as_dcm()\n",
    "        T_G_C = np.eye(4).astype(float)\n",
    "        T_G_C[:3,:3] = rotation\n",
    "        T_G_C[:3,3] = [translation.x,translation.y,translation.z]\n",
    "        pose_list.append(T_G_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Semantic and depth segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_SHAPES                [[256 256]\n",
      " [128 128]\n",
      " [ 64  64]\n",
      " [ 32  32]\n",
      " [ 16  16]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /home/yang/anaconda3/envs/py27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yang/anaconda3/envs/py27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yang/anaconda3/envs/py27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yang/anaconda3/envs/py27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3661: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yang/anaconda3/envs/py27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1944: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yang/thesis_test/toolbox/voxbloxpp_ws/src/mask_rcnn_ros/src/mask_rcnn_ros/model.py:382: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/yang/thesis_test/toolbox/voxbloxpp_ws/src/mask_rcnn_ros/src/mask_rcnn_ros/model.py:406: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /home/yang/thesis_test/toolbox/voxbloxpp_ws/src/mask_rcnn_ros/src/mask_rcnn_ros/model.py:711: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/yang/thesis_test/toolbox/voxbloxpp_ws/src/mask_rcnn_ros/src/mask_rcnn_ros/model.py:737: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/yang/anaconda3/envs/py27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:168: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yang/anaconda3/envs/py27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:175: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yang/anaconda3/envs/py27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:180: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yang/anaconda3/envs/py27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:184: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yang/anaconda3/envs/py27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:193: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yang/anaconda3/envs/py27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:200: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# initialized segmentors\n",
    "height = depth_image_list[0].shape[0]\n",
    "width = depth_image_list[0].shape[1]\n",
    "K_depth = np.array(depth_cam_info.K).reshape(3,3)\n",
    "segmentor = depth_seg_utils.depth_segmentation_py.DepthSegmentation_py(height,width,cv2.CV_32FC1, K_depth)\n",
    "\n",
    "node = semantic_seg_utils.MaskRCNNNode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. map integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = frame2Segments(segmentor, node, depth_image_list[0], rgb_image_list[0],pose_list[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('max dis: ', 2.1940608072590515)\n",
      "('mean dis: ', 1.8363727359320507)\n",
      "('median dis: ', 1.8185875611457971)\n"
     ]
    }
   ],
   "source": [
    "# inspect segments\n",
    "seg_test = test[0]\n",
    "point_distance = np.linalg.norm(seg_test.points, axis=1)\n",
    "print(\"max dis: \", np.max(point_distance))\n",
    "print(\"mean dis: \", np.mean(point_distance))\n",
    "print(\"median dis: \", np.median(point_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "# import python module of depth_segmentation\n",
    "lib_path = \"/home/yang/thesis_test/toolbox/voxbloxpp_ws/devel/lib\"\n",
    "sys.path.append(lib_path)\n",
    "\n",
    "import gsm_py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = os.path.abspath(\"./result\")\n",
    "gsm_node = gsm_py.GlobalSegmentMap_py(log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yang/thesis_test/toolbox/voxbloxpp_ws/src/voxblox-plusplus/global_segment_map_py/scripts/result'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for segment in test[1:]:\n",
    "    gsm_node.insertSegments(segment.points,segment.colors, segment.geometry_confidence,\n",
    "        segment.instance_label,segment.class_label, segment.label_confidence,segment.pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26622, 3)\n",
      "(26622, 3)\n",
      "(26622, 1)\n",
      "0\n",
      "1\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(segment.points.shape)\n",
    "print(segment.colors.shape)\n",
    "print(segment.geometry_confidence.shape)\n",
    "print(segment.instance_label)\n",
    "print(segment.label_confidence)\n",
    "print(segment.pose.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "gsm_node.generateMesh(log_file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7108878b0b45ca5dc81c19f8bc062d0841caf012e682ee22546f321fe11bcc5"
  },
  "kernelspec": {
   "display_name": "Python 2.7.15 ('py27')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
